---
title: "Parallel Trends Pre-Checks"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.width=15, fig.height=10) 
```

In this script we walk through boilerplate causal pre-checks to determine if our data meets the parallel trends assumption in the pre period. We only look at the most essential functions as there are many more esoteric checks contained in our helper script documented below that are likely not always necessary. Please see the appendix for a list of functions and their use.

###### Steps ######
1. Basic visual inspection of pre/post campaign to examine parallel trends assumption.
2. Analysis of variance in pre/post sales data.
3. Optional: Event study comparison to determine the difference between between pre/post, which helps us determine if the difference is a function of surrounding time periods OR the intervention.
4. We use linear regression to compare pre-intervention trends between groups.

```{r load_packages, warnings=FALSE, message=FALSE}

# Load required packages
packages <- c(
  "dplyr",
  "tidyr",
  "tidyverse",
  "patchwork",
  "broom",
  "CausalImpact",
  "scales",
  "lubridate",
  "lmtest",
  "sandwich",
  "fixest",
  "car",
  "feasts",
  "infer",
  "corrr",
  "kableExtra",
  "slider"
)

installed <- rownames(installed.packages())
to_install <- setdiff(packages, installed)

if (length(to_install) > 0) {
  install.packages(to_install)
}

suppressPackageStartupMessages(
  lapply(packages, library, character.only = TRUE)
)

# Set seed for synthetic data gen and model fitting
set.seed(7)

# Load theme
source("/Users/karstenwalker/Documents/GitHub/R/Helpers/themes.R")

# Load causal pre-check function
source("/Users/karstenwalker/Documents/GitHub/R/Causal/causal_pre_check.R")

```


```{r data}
teacher_signups<-read.csv(file="/Users/karstenwalker/Downloads/teacher_signups.csv")%>%
  mutate(date=ymd(date),
         treat=as.factor(ifelse(country_code=="US",1,0)),
         intervention_date=ymd("2026-01-06"),
         post=ifelse(date>="2026-01-06",1,0),
         num_teachers=ifelse(country_code=="CA", num_teachers/20, num_teachers),
         num_teacher_signups=ifelse(country_code=="CA", num_teacher_signups/20, num_teacher_signups),
         log_teachers=log1p(num_teachers),
         log_signups=log1p(num_teacher_signups)
         )%>%
  group_by(country_code)%>%
  arrange(date)%>%
  mutate(num_teachers_7d = slide_dbl(
                                .x = num_teachers,
                                .f = mean,
                                .before = 7, # Includes the current row (.before=0) and the two preceding rows
                                .after = 0,
                                .complete = FALSE ),
         num_teachers_signups_7d = slide_dbl(
                                .x = num_teacher_signups,
                                .f = mean,
                                .before = 7, # Includes the current row (.before=0) and the two preceding rows
                                .after = 0,
                                .complete = FALSE ))%>%
  group_by(date)%>%
  mutate(total_teachers=sum(num_teachers),
         total_signups=sum(num_teacher_signups))%>%
  ungroup()%>%
  group_by(country_code, date)%>%
  mutate(pct_teachers=sum(num_teachers)/total_teachers,
         pct_signups=sum(num_teacher_signups)/total_signups)%>%
  ungroup()

teacher_pct<-read.csv(file="/Users/karstenwalker/Downloads/teacher_pct.csv")

intervention_date<-ymd("2026-01-06")

```

Let's check out our data real quick
```{r data_check}
report::report(teacher_signups%>%
                 select(-date,-intervention_date))

kbl(teacher_signups %>%
  group_by(country_code) %>%
  summarize(
    mean_teachers = mean(num_teacher_signups, na.rm = TRUE),
    med_teachers = median(num_teacher_signups, na.rm = TRUE),
    min_teachers= min(num_teacher_signups, na.rm = TRUE),
    max_teachers= max(num_teacher_signups, na.rm = TRUE),
    sd_teachers = sd(num_teacher_signups),
    mean_pct_teachers = mean(pct_teachers, na.rm = TRUE),
    med_pct_teachers = median(pct_teachers, na.rm = TRUE),
    min_pct_teachers= min(pct_teachers, na.rm = TRUE),
    max_pct_teachers= max(pct_teachers, na.rm = TRUE),
    sd_pct_teachers = sd(pct_teachers)
  )%>%
  arrange(country_code))%>%
  kable_minimal()

```
On face value the difference in SD between the US and Canada on total signups is somewhat concerning.

Overall pre/post visual check
```{r overall}
us_signups<-teacher_signups %>%
  filter(country_code=="US")%>%
  ggplot(aes(x = date, y = num_teachers_signups_7d)) +
  geom_line(linewidth = 1, color ="lightgreen") +
  geom_vline(xintercept = intervention_date, linetype = "dashed") +
  geom_smooth()+
  labs(
    title = "Parallel Trends Check: Treated vs Control",
    x = "Date",
    y = "7D Rolling Average",
    color = "Country"
  ) +
  theme_fancy()

ca_signups<-teacher_signups %>%
  filter(country_code!="US")%>%
  ggplot(aes(x = date, y = num_teachers_signups_7d)) +
  geom_line(linewidth = 1, color = "lightblue") +
  geom_vline(xintercept = intervention_date, linetype = "dashed") +
  geom_smooth()+
  labs(
    title = "",
    x = "",
    y = "",
    color = ""
  ) +
  theme_fancy()

us_signups/ca_signups

log_us_signups<-teacher_signups %>%
  filter(country_code=="US")%>%
  ggplot(aes(x = date, y = log_signups)) +
  geom_line(linewidth = 1, color ="lightgreen") +
  geom_vline(xintercept = intervention_date, linetype = "dashed") +
  geom_smooth()+
  labs(
    title = "Parallel Trends Check: Treated vs Control",
    x = "Date",
    y = "7D Rolling Average",
    color = "Country"
  ) +
  theme_fancy()

log_ca_signups<-teacher_signups %>%
  filter(country_code!="US")%>%
  ggplot(aes(x = date, y = log_signups)) +
  geom_line(linewidth = 1, color = "lightblue") +
  geom_vline(xintercept = intervention_date, linetype = "dashed") +
  geom_smooth()+
  labs(
    title = "",
    x = "",
    y = "",
    color = ""
  ) +
  theme_fancy()

log_us_signups/log_ca_signups


```

If we use a 7D rolling average to smooth out daily/weekly seasonality we can see numerous differences in pre-period trends, especially in the prior 3 months.

The logged data follows a similar pattern. In this case we prefer to use a logged metric since there is a stark difference in scale between the groups.

```{r diffs}
num<-teacher_signups%>%
  select(date, country_code, num_teacher_signups)%>%
  pivot_wider(names_from = country_code, values_from = num_teacher_signups)%>%
  group_by(date)%>%
  summarize(diff=US-CA)%>%
  ggplot()+
  aes(x=date, y=diff)+
  geom_line(linewidth = 1)+
  labs(title="Difference Between Teachers, US Vs. CA",
       subtitle="Raw Count")+
  theme_fancy()

log<-teacher_signups%>%
  select(date, country_code, log_signups)%>%
  pivot_wider(names_from = country_code, values_from = log_signups)%>%
  group_by(date)%>%
  summarize(diff=US-CA)%>%
  ggplot()+
  aes(x=date, y=diff)+
  geom_line(linewidth = 1)+
  labs(subtitle="Log Scale")+
  theme_fancy()

num/log

```

Quick visual seasonality check shows there is not day-of-week seasonality, but clear seasonality we baked into the data. We added a noise component so that we can identify if these checks are able to separate out normal variance over a longer period.
```{r seas}
# Day-of-week
day<-teacher_signups %>%
  filter(date<="2026-01-06")%>%
  mutate(group = if_else(treat==1,"Treated","Control"),
         wday = weekdays(date)) %>%
  group_by(wday, group) %>%
  summarize(mean_teachers = mean(num_teacher_signups)) %>%
  mutate(mean_teachers=ifelse(group=="Control", mean_teachers*50, mean_teachers))%>%
  ggplot(aes(wday, mean_teachers, fill = group)) +
  geom_col(position = position_dodge())+
  labs( title = "Day of Week Teachers",
        x = "Group (0 = Control, 1 = Treated)",
        y = "Teachers") +
  theme_fancy()

# Month
mo<-teacher_signups %>%
  filter(date<="2026-01-06")%>%
  mutate(group = if_else(treat==1,"Treated","Control"),
         month = format(date, "%m")) %>%
  group_by(month, group) %>%
  summarize(mean_teachers = mean(num_teacher_signups)) %>%
  ungroup()%>%
  mutate(mean_teachers=ifelse(group=="Control", mean_teachers*50, mean_teachers))%>%
  ggplot(aes(month, mean_teachers, group=group, color=group)) + 
  geom_line(size=1.1)+
  geom_vline(xintercept = 11, linetype="dashed", color="red") +
  labs( title = "Monthly Teacher Avg",
        x = "Group (0 = Control, 1 = Treated)",
        y = "Avg Teachers") +
  theme_fancy()

day/mo

log_day<-teacher_signups %>%
  filter(date<="2026-01-06")%>%
  mutate(group = if_else(treat==1,"Treated","Control"),
         wday = weekdays(date)) %>%
  group_by(wday, group) %>%
  summarize(mean_teachers = mean(log_signups)) %>%
  mutate(mean_teachers=ifelse(group=="Control", mean_teachers*50, mean_teachers))%>%
  ggplot(aes(wday, mean_teachers, fill = group)) +
  geom_col(position = position_dodge())+
  labs( title = "Day of Week Teachers (Log 1p scale)",
        x = "Group (0 = Control, 1 = Treated)",
        y = "Teachers") +
  theme_fancy()

# Month
log_mo<-teacher_signups %>%
  filter(date<="2026-01-06")%>%
  mutate(group = if_else(treat==1,"Treated","Control"),
         month = format(date, "%m")) %>%
  group_by(month, group) %>%
  summarize(mean_teachers = mean(log_signups)) %>%
  ungroup()%>%
  mutate(mean_teachers=ifelse(group=="Control", mean_teachers*50, mean_teachers))%>%
  ggplot(aes(month, mean_teachers, group=group, color=group)) + 
  geom_line(size=1.1)+
  geom_vline(xintercept = 11, linetype="dashed", color="red") +
  labs( title = "Monthly Teacher Avg (Log 1p scale)",
        x = "Group (0 = Control, 1 = Treated)",
        y = "Avg Teachers") +
  theme_fancy()

log_day/log_mo

```

Unfortunately we do have some slightly different day-of-week and monthly average teacher variance.

The next thing we need to do is check for auto-correlation between time series. This would be a concern if we introduced some kind of incentive for the treatment and there was contamination in the control and potential exposure from network effects or de-linked user/session IDs.

```{r autocorre}
library(feasts) 

teachers_ts <- teacher_signups %>%
  mutate(group = if_else(treat==1,"Treated","Control"))%>%
  ungroup()%>%
  as_tsibble(key = group, index = date)   

# ACF
acf_df <- teachers_ts %>%
  ACF(log_signups)

# PACF
pacf_df <- teachers_ts %>%
  PACF(log_signups)

# Plot
acf_fig <- acf_df %>%
  autoplot() +
  labs(title = "ACF by Treatment Group")+
  theme_fancy()

pacf_fig <- pacf_df %>%
  autoplot()+
  labs(title = "PACF by Treatment Group")+
  theme_fancy()

acf_fig/pacf_fig

```

Nothing alarming that we did not already know.

Normally this is where I would run Levene's test to measure variance and the Kolmogorov–Smirnov (KS) test to compare the distributions between two groups. Levene's test is not appropriate because they assume many independent observations per group. In a 1 treated/1 control geo setting, the KS test is not a meaningful parallel-trends diagnostic because there is no within-time distribution to compare (each group contributes one observation per date), and pooling over time confounds time dynamics with distributional shape.

Instead, we rely on gap-based, time-aware diagnostics (event study, differential trend tests, and rolling gap stability as above).

The first thing that we want to understand is whether the treated–control gap is stable in the pre-period. With one treated geography and one control geography, tests like Levene/Fligner (equal variances across groups) are not appropriate because they assume many independent observations per group. Instead, we look at the rolling variance of the treated–control gap in the pre-period. A flat line would indicate that the delta never differs and a very jagged line means that the standard deviation dramatically varies over a 7 day period

```{r rolling_gap_variance}

intervention_date <- as.Date("2026-01-06")

gap_pre <- teacher_signups %>%
  mutate(log_teachers = log1p(num_teacher_signups),
    rel_time = as.integer(date - intervention_date)) %>%
  filter(rel_time < 0) %>%
  group_by(date, treat) %>%
  summarise(y = mean(log_teachers, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = treat, values_from = y) %>%
  transmute(date = date, gap = `1` - `0`) %>%
  arrange(date) %>%
  mutate(roll_sd_7 = slide_dbl(gap, sd, .before =6, .complete = TRUE),
         roll_var_7 = roll_sd_7^2
  )

ggplot(gap_pre, aes(x = date, y = roll_sd_7)) +
  geom_line(linewidth = 1) +
  labs(
    title = "7-day Rolling SD of Treated–Control Gap (Pre-period)",
    x = "Date",
    y = "Rolling SD of gap (log1p)"
  ) +
  theme_fancy()
```


This plot is a simple, time-series–appropriate variance diagnostic test. If the gap’s rolling mean and rolling SD drift a lot in the pre-period, that’s evidence of instability and potential parallel-trends concerns.

```{r gap_series_plot}
# Build treated–control gap series on log scale
gap_df <- teacher_signups %>%
  mutate(log_teachers = log1p(num_teacher_signups)) %>%
  group_by(date, treat) %>%
  summarise(mean_log_teachers = mean(log_teachers, na.rm = TRUE), .groups = "drop") %>%
  tidyr::pivot_wider(names_from = treat, values_from = mean_log_teachers) %>%
  transmute(date = date, gap = `1` - `0`) %>%
  arrange(date) %>%
  filter(date < intervention_date) %>%
  mutate(roll_mean_7 = slide_dbl(gap, mean, .before = 6, .complete = TRUE),
         roll_sd_7   = slide_dbl(gap, sd,   .before = 6, .complete = TRUE)
  )

# Rolling mean of the pre-period gap
mean_plot<-ggplot(gap_df, aes(x = date, y = roll_mean_7)) +
  geom_line() +
  labs(
    title = "Pre-period treated–control gap, 7-day rolling mean, log1p)",
    x = "",
    y = "Rolling Mean of gap"
  ) +
  theme_fancy()

# Rolling SD of the pre-period gap
sd_plot<-ggplot(gap_df, aes(x = date, y = roll_sd_7)) +
  geom_line() +
  labs(
    title = "Pre-period treated–control, 7-day rolling mean, log1p",
    x = "Date",
    y = "Rolling SD of gap"
  ) +
  theme_fancy()

mean_plot/sd_plot
```

Finally we run an Event Study, which is really just a fancy form of linear regression, but provides us with cluster-robust standard errors because we have multiple treated and control units. If we just had 1 of each we could just use regression with the equation sales ~ post. We are careful to estimate the treatment effect in treated vs control for every relative time period around the intervention. The coefficients should cluster around 0.

```{r event}
# Create relative time (days to/from intervention)
# For 2 or more groups
#  1. Keep only pre-period
#  2. Interact event time × treatment
#  3. Normalize one pre-period bin (e.g. rel_time = -1)

teacher_signups_es <- teacher_signups %>%
  mutate(
    rel_time = as.integer(date - intervention_date),
    log_teachers = log1p(num_teacher_signups)
  ) %>%
  filter(rel_time < 0) %>%
  mutate(
    rel_time_bin = case_when(
      rel_time <= -180 ~ -180,
      rel_time >= -1   ~ -1,
      TRUE ~ rel_time
    ),
    rel_time_bin = factor(rel_time_bin)
  )

# Each coefficient = (Treated − Control) at that relative time − (Treated − Control) at rel_time = −1
# So flat pre-coefficients ≈ parallel trends.

es <- feols(
  log_teachers ~ i(rel_time_bin, treat, ref = "-1") |
    country_code + date,          # <-- critical
  data = teacher_signups_es,
  cluster = ~ country_code
)

event_df <- broom::tidy(es, conf.int = TRUE) %>%
  filter(str_detect(term, "rel_time")) %>%
  mutate(rel_time = as.integer(str_extract(term, "-?\\d+"))) %>%
  arrange(rel_time)

ggplot(event_df, aes(x = rel_time, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Event-Study: Pre/Post Treatment Effects ",
    x = "Days Relative to Treatment",
    y = "Estimated Effect"
  ) +
  theme_fancy()

```

- **Early pre-period (≈ −180 to −140)**
  - Coefficients are flat and slightly negative.
  - Very tight clustering.
  - Stable relative growth.

- **Mid pre-period (≈ −140 to −110)**
  - Sharp, systematic dip
  - This is not noise: treated countries experienced a large relative decline compared to controls long before treatment.
  - This is a clear violation of parallel trends.

```{r salesreg}
pre_data <- teacher_signups %>%
  mutate(
    rel_time = as.integer(date - intervention_date),
    log_teachers = log1p(num_teacher_signups)
  ) %>%
  filter(rel_time < 0)

pre_trend_test <- feols(
  log_teachers ~ rel_time * treat | country_code,
  data = pre_data,
  cluster = ~ country_code
)

summary(pre_trend_test)

```

rel_time:treat1 = −0.000461 indicates that there is a difference in slopes between treated and control of ~0.11% decline per day for treated units (Treated countries’ pre-period slope is:−0.000639−0.000461=−0.00110). This difference is highly statistically significant.

That's it! We have accounted for:

* Equal variance in the pre-period.
* Autocorrelation.
* A consistent difference in the pre-period trend.
* Determining if the difference is significant with either an Event Study or Linear Regression.

Now instead of running this code over and over I have written a helper function that runs all these tests and returns the results.

```{r diag, warning=FALSE}

diag_results_panel <- pre_treatment_diagnostics_panel(
  data = teacher_signups,
  outcome = "num_teacher_signups",
  treat = "treat",
  time = "date",
  unit = "country_code",
  intervention_date = as.Date("2026-01-06"),
  transform = "log1p",
  do_event_study = TRUE
)

diag_results_panel$summary_table
```

```{r gapseries}
diag_results_panel$gap_series
```

```{r rollingdf}
diag_results_panel$gap_rolling_df
```

```{r rollingplot}
diag_results_panel$gap_rolling_plot
```

```{r summarytab}
diag_results_panel$results$summary_table
```

```{r es_plot}
diag_results_panel$results$event_study_plot
```

```{r seasonalityslope}
diag_results_panel$results$seasonality_slope_plot
```

```{r curve}
diag_results_panel$results$curvature_plot
```


## Diagnostic summary table

```{r diagnostic_summary_table, message=FALSE, warning=FALSE}
suppressPackageStartupMessages({
  library(dplyr)
  library(tibble)
  library(knitr)
  library(fixest)
})

# ------------------------------------------------------------
# Helpers
# ------------------------------------------------------------

# Safely extract a p-value from many object types
get_p <- function(x) {
  if (is.null(x)) return(NA_real_)

  # Already a numeric p-value
  if (is.atomic(x) && length(x) == 1 && is.numeric(x)) {
    return(as.numeric(x))
  }

  # htest objects
  if (inherits(x, "htest")) {
    return(as.numeric(x$p.value))
  }

  # list-like objects that store p.value
  if (is.list(x) && !is.null(x$p.value)) {
    return(as.numeric(x$p.value))
  }
  if (is.list(x) && !is.null(x[["p.value"]])) {
    return(as.numeric(x[["p.value"]]))
  }

  NA_real_
}

# Safely extract a coefficient p-value from a fixest model
get_fixest_coef_p <- function(mod, coef_pattern) {
  if (is.null(mod)) return(NA_real_)
  ct <- tryCatch(fixest::coeftable(mod), error = function(e) NULL)
  if (is.null(ct)) return(NA_real_)
  rn <- rownames(ct)
  hit <- grep(coef_pattern, rn)
  if (length(hit) == 0) return(NA_real_)
  pv <- ct[hit, "Pr(>|t|)"]
  suppressWarnings(min(as.numeric(pv), na.rm = TRUE))
}

# ------------------------------------------------------------
# Convenience handles from wrapper output
# ------------------------------------------------------------

gap_roll <- diag_results_panel$gap_rolling_df
gap_plot_present <- !is.null(diag_results_panel$gap_rolling_plot)

# Legacy models / values returned by pre_treatment_diagnostics()
lin_mod    <- diag_results_panel$results$slope_model
curv_p     <- diag_results_panel$results$curvature_p_value
season_p   <- diag_results_panel$results$seasonality_slope_p_value

# NOTE: This is placebo, not pre-leads (kept for transparency)
placebo_p  <- diag_results_panel$results$placebo_leads_p_value

# ------------------------------------------------------------
# Rolling gap summary stats (pre-period)
# ------------------------------------------------------------

roll_sd_mean <- if (!is.null(gap_roll)) mean(gap_roll$roll_sd, na.rm = TRUE) else NA_real_
roll_sd_max  <- if (!is.null(gap_roll)) max(gap_roll$roll_sd,  na.rm = TRUE) else NA_real_
roll_mean_abs_max <- if (!is.null(gap_roll)) max(abs(gap_roll$roll_mean), na.rm = TRUE) else NA_real_

# ------------------------------------------------------------
# Single 1v1 wrapper summary table
# ------------------------------------------------------------

summary_1v1 <- tibble::tribble(
  ~diagnostic, ~type, ~value, ~object_path, ~notes,

  "Event study model (pre-period)",
  "model",
  NA_real_,
  "diag_results_panel$results$event_study_model",
  "Primary visual diagnostic; inspect pre-period coefficients.",

  "Event study plot",
  "plot",
  NA_real_,
  "diag_results_panel$results$event_study_plot",
  "Pre-period coefficients should be flat and near zero.",

  "Pre-leads joint test (event study)",
  "p-value",
  NA_real_,
  "diag_results_panel$results$event_study_preleads_p_value",
  "Not currently stored; add wald() on pre leads to populate.",

  "Placebo leads joint test (FYI)",
  "p-value",
  get_p(placebo_p),
  "diag_results_panel$results$placebo_leads_p_value",
  "Placebo check only; not a substitute for pre-leads test.",

  "Linear differential pretrend (slope interaction)",
  "p-value",
  get_fixest_coef_p(lin_mod, "time_num:treat|rel_time:treat|:treat"),
  "diag_results_panel$results$slope_model",
  "Time-series diagnostic on collapsed treated–control series.",

  "Curvature / nonlinearity in pretrend",
  "p-value",
  get_p(curv_p),
  "diag_results_panel$results$curvature_p_value",
  "Detects nonlinear drift in the treated–control gap.",

  "Seasonality-adjusted pretrend",
  "p-value",
  get_p(season_p),
  "diag_results_panel$results$seasonality_slope_p_value",
  "Adjusts for weekly seasonality in daily data.",

  "Gap rolling SD (mean)",
  "stat",
  roll_sd_mean,
  "diag_results_panel$gap_rolling_df$roll_sd",
  "Stability of gap volatility (replaces variance-equality tests).",

  "Gap rolling SD (max)",
  "stat",
  roll_sd_max,
  "diag_results_panel$gap_rolling_df$roll_sd",
  "Large spikes indicate instability windows.",

  "Gap rolling mean |max|",
  "stat",
  roll_mean_abs_max,
  "diag_results_panel$gap_rolling_df$roll_mean",
  "Large magnitude indicates drifting treated–control gap.",

  "Gap rolling plot available",
  "flag",
  as.numeric(gap_plot_present),
  "diag_results_panel$gap_rolling_plot",
  "1 = available, 0 = missing"
) %>%
  mutate(
    value = if_else(is.nan(value), NA_real_, value),
    value_fmt = case_when(
      type == "p-value" ~ if_else(is.na(value), NA_character_, formatC(value, format = "f", digits = 4)),
      type == "stat"    ~ if_else(is.na(value), NA_character_, formatC(value, format = "f", digits = 4)),
      type == "flag"    ~ if_else(is.na(value), NA_character_, as.character(as.integer(value))),
      TRUE              ~ NA_character_
    )
  ) %>%
  select(diagnostic, type, value_fmt, object_path, notes) %>%
  rename(value = value_fmt)

# ------------------------------------------------------------
# Print table
# ------------------------------------------------------------

knitr::kable(
  summary_1v1,
  align = c("l", "l", "l", "l", "l"),
  caption = "1v1 (single treated + single control) pre-treatment diagnostics summary"
)


```


